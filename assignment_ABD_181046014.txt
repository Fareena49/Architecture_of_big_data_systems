1. Load batting.csv into a mysql in a database battingdb and table batting
create database battingdb;
use battingdb;
create table batting(playerID varchar(30),yearID int,stint int,teamID varchar(10),lgID varchar(10), G int, G_batting int,AB int,R int,H int,2B int,3B int,HR int,RBI int,SB int,CS int,BB int,SO int,IBB int,HBP int,SH int,SF int,GIDP int,G_old int);
Load data infile '/home/cloudera/Lab/DataFiles/Batting1.csv' into table batting fields terminated by ',' Lines terminated by '\n';
2. Sqoop the details into hdfs.
sqoop import --connect jdbc:mysql://localhost/battingdb --username root --password cloudera --table batting --m 1
hadoop fs -cat /user/cloudera/batting/part-m-00000;
3. Sqoop the details into hive.
	>>hive;
  create database battingdb;
 use battingdb;
create table batting2(playerID STRING,yearID int,stint int,teamID STRING,lgID STRING,G int,G_batting int,AB int,R int,H int,B2 int,B3 int,HR int,RBI int,SB int,CS int,BB int,SO int,IBB int,HBP int,SH int,SF int,GIDP int,G_old int) row format delimited fields terminated by ',' stored as textfile;
LOAD DATA LOCAL INPATH '/home/cloudera/Lab/DataFiles/Batting1.csv' into table batting;
4. Implement a PIG script to 
a) Find the total count of participation of G 112
batting_list = LOAD '/home/cloudera/Lab/DataFiles/Batting1.csv' USING PigStorage(',') as (playerID:chararray,yearID:int,stint:int,teamID:chararray,lgID:chararray,G:int,G_batting:int,AB:int,R:int,H:int,B2:int,B3:int,HR:int,RBI:int,SB:int,CS:int,BB:int,SO:int,IBB:int,HBP:int,SH:int,SF:int,GIDP:int,G_old:int);
	dump batting_list;
count_g = FILTER batting_list BY G == 112;
group_count_g  = GROUP count_g All;
	total_count = foreach group_count_g Generate COUNT(count_g.G);
dump total_count;
	store total_count  into 'count_g112';
	b)david  = Filter batting_list by(playerID MATCHES 'david.*');
	dump david;

b) Find the player details with "david" 
c) Find the average count of "NL"
NL_filter = Filter batting_list by lgID =='NL';
	NL_Group = Group NL_filter All;
	NL_avg = foreach NL_Group Generate AVG(NL_filter.G_batting);
	DUMP NL_avg
	
d) Find the count of teams;
	team_count = GROUP batting_list by teamID;
	team_group = GROUP team_count All;
	result_count = Foreach team_group Generate COUNT(team_count);
	dump result_count
5. Implement a Hive script to
a) Find the total count of player details with "david"
select count(*) from batting where playerID REGEXP 'david[a-z]*';
clustered by (playerID) INTO 3 buckets
b) Create a patition on the TEAMID
c) Create 3 buckets on the partition.
create table batting_part2(playerID STRING, yearID INT, stint INT, lgID STRING, G INT, G_batting INT, AB INT, R INT, H INT, twoB INT, threeB INT, HR INT, RBI INT, SB INT, CS INT, BB INT, SO INT, IBB INT, HBP INT, SH INT, SF INT, GIDP INT, G_old INT) 
partitioned by(teamID STRING) 
row format delimited 
fields terminated by ',' 
lines terminated by '\n';
set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing=true;
	
d) Extract the details on player "aaronha01"
from batting1 ba INSERT OVERWRITE TABLE batting_part2 PARTITION(teamID) select ba.playerID, ba.yearID, ba.stint, ba.lgID, ba.G, ba.G_batting, ba.AB, ba.R, ba.H, ba.B2, ba.B3, ba.HR, ba.RBI, ba.SB, ba.CS, ba.BB, ba.SO, ba.IBB, ba.HBP, ba.SH, ba.SF, ba.GIDP, ba.G_old, ba.teamID  DISTRIBUTE BY teamID;
from txnrecords txn INSERT OVERWRITE TABLE txnrecsByCat PARTITION(category)
select txn.txnno, txn.txndate,txn.custno, txn.amount,txn.product,txn.city,txn.state,
txn.spendby, txn.category DISTRIBUTE BY category;
e) Find the count of teams

6) Using python, 
a) Write a map-reducer program to find the total count of the players
#get_ipython().run_line_magic('tb', '')
from mrjob.job import MRJob
from mrjob.step import MRStep
import sys  
class MRWordFrequencyCount(MRJob):
	def mapper1(self, _, lines):
		data = lines.split(',')
		players = data[0].strip()
		yield players,None	
	def combiner(self, word, counts):
		yield word,None			
	def reducer1(self, key, counts):
		yield "total players",key
	def reducer2(self, key,word):
		c =0
		# for i in word:
		# c+=1		
		yield key,len(list(word))
	def steps(self):
return [ MRStep(mapper=self.mapper1,reducer=self.combiner),MRStep(reducer=self.reducer1),MRStep(reducer=self.reducer2)]
if __name__ == '__main__':
MRWordFrequencyCount.run()

b) Write a map-reducer program to find the total number of the teams.
#get_ipython().run_line_magic('tb', '')
from mrjob.job import MRJob
from mrjob.step import MRStep
import sys  
class MRWordFrequencyCount(MRJob):
	def mapper1(self, _, lines):
		data = lines.split(',')
		players = data[3].strip()
		yield players,None	
	def combiner(self, word, counts):
		yield word,None			
	def reducer1(self, key, counts):
		yield "total teams",key
	def reducer2(self, key,word):
		c =0
		for i in word:
		c+=1	
		yield key,c
	def steps(self):
return [ MRStep(mapper=self.mapper1,reducer=self.combiner),MRStep(reducer=self.reducer1),MRStep(reducer=self.reducer2)]
if __name__ == '__main__':
    MRWordFrequencyCount.run()
8. From halloffame.csv
a) List the managers.
	from mrjob.job import MRJob

	class MRmyjob(MRJob):
	def mapper(self,_,line):
		#split the line with tab separated fields
		data = line.split(',')
		hofid = data[0].strip()
		category = data[7].strip()
		if category == 'Manager':
			yield hofid,None
		
	

	def reducer(self, key, list_of_values):
		
		yield "manager",key
	
	if __name__ == '__main__':
	MRmyjob.run();

b) Find the numbers of votes got year wise by "chancfr01h".
from mrjob.job import MRJob



class MRmyjob(MRJob):
	def mapper(self,_,line):
		#split the line with tab separated fields
		data = line.split(',')
		hofid = data[0].strip()
		year = data[1].strip()
		votes = data[5].strip()
		if hofid == 'chancfr01h':
			try:
				yield year,int(votes)
			except:
				yield year,0
	def reducer(self, key, list_of_values):
		yield key,sum(list_of_values)

if __name__ == '__main__':
	

c) Count the votes got by each person overall.
MRmyjob.run();
	from mrjob.job import MRJob

	class MRmyjob(MRJob):
	    def mapper(self,_,line):
		#split the line with tab separated fields
		data = line.split(',')
		hofid = data[0].strip()
		year = data[1].strip()
		votes = data[5].strip()
		try:
			yield hofid,int(votes)
		except:
			yield hofid,0
		
	   def reducer(self,key,list_of_values):
		yield key,sum(list_of_values)

	if __name__ == '__main__':
	MRmyjob.run();

7)  Visualize the battings.csv based on the frequency of palyer inclusion yearwise.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
dataset = pd.read_csv('Batting.csv')
dataset.head(5)
df1 = dataset.groupby('yearID')['playerID'].count()
plt.figure(figsize=(15,10),dpi=100)
plt.plot(df1, linestyle='dotted', marker = '*', color = 'blue', label = 'Players')
plt.xlabel('Year')
plt.ylabel('Players Included')
plt.show()
9. Using hive,partition by year. Then, find the year wise count of participants, find the total votes got by the players.

	create table halloffame(hofID STRING, yearid INT, votedBy STRING, ballots INT, needed INT, votes INT,inducted STRING, category STRING, needed_note STRING) row format delimited fields terminated by ',' stored as textfile;
	LOAD DATA LOCAL INPATH '/home/cloudera/Lab/DataFiles/HallOfFame.csv' into table halloffame;
	set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing=true;

	create table halloffame_part hof(hofID STRING, votedBy STRING, ballots INT, needed INT, votes INT,inducted STRING, category STRING, needed_note STRING) partitioned by(yearid INT) row format delimited fields terminated by ',' lines terminated by '\n';

	from halloffame hof INSERT OVERWRITE TABLE halloffame_part PARTITION(yearid) select hof.hofID, hof.votedBy, hof.ballots, hof.needed, hof.votes, hof.inducted, hof.category, hof.needed_note, hof.yearid  DISTRIBUTE BY yearid;

	select yearid, count(hofid) from halloffame_part group by yearid;
	select hofid, sum(votes) from halloffame_part group by hofid;


10. Using python, map-reducer, find the average votes on the year 1936.
	from mrjob.job import MRJob
	class MRmyjob(MRJob):
	    def mapper(self,_,line):
			#split the line with tab separated fields
		data = line.split(',')
		date = data[1].strip()
		votes = data[5].strip()
		if date == '1936':
			yield "votes",votes
		
	   
	     def reducer(self, key, list_of_values):
		count = 0
		total = 0
		for x in list_of_values:
			total = total + float(x);
			count = count+1
			avglen = ("%.2f" % (total / count))
		yield key,avglen
	
	if __name__ == '__main__':
	  MRmyjob.run();

